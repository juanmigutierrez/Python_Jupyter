{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Miguel Gutierrez y Daniel Rambaut\n",
    "\n",
    "# Proyecto IV: Chatbot\n",
    "\n",
    "EL objetivo de este poryecto es desarrollar un sistema de dialogo tipo **chatbot** utilizando las herramientas vistas en clase. EL sistema debe contener un modeulo de atención, el cual incluira información historica del chat en uno o más vectores caracteristicos, junto con la codificación de la palabra escpecificada. Ademas se hará uso de una red LSTM para la generación de texto, de forma similar a como se hizó en el proyecto pasado. \n",
    "\n",
    "Para el desarrollo de este proyecto deben seguir lso siguientes pasos:\n",
    "\n",
    "1. Crear el corpus de entrenamiento. Esto se hace en conjunto con los demás grupos del curso.\n",
    "2. Diseñar la estrategia de atención, aqui ustedes definen el número de vectores historicos qu eutilian, como los calculan, la longitud del historial, etc...\n",
    "3. Deben crear el sistema de generación de texto, el cual permita establecer un dialogo con el computador.\n",
    "4. Deben organizar el código de tal forma que permit ala interacción con el y se pueda establecer una comunicación adecuada. Es decir, deben generar una función que reciba como entrada una frase, que la respuesta sea la generación de texto del chatbot, y que al colocarle la siguiente frase de entrada, se almacene en el historial la conversación que se lleva hasta el momento, para que el sistema pueda responder de forma adecuada.\n",
    "\n",
    "Al finalizar la implementación deben responder las siguientes preguntas:\n",
    "\n",
    "1. ¿Qué diferencias encuentran en el sistema de generación de texto de este proyecto, comparado con el del proyecto anterior?\n",
    "2. ¿Considera qu ela estrategia de atención mejora el rendimiento del sistema de generación de texto? Justifique su respuesta.\n",
    "3. ¿Son los resultados obtenidos satisfactorios? ¿Cómo mejoraria los resultados del sistema implementado?\n",
    "4. Si se les solicitará en sus trabajos utilizar los conocimientos que adquirieron en NLP para proponer propuestas de desarrollos y mejorar la competitividad de sus empresas, ¿Qué proyectos propondrian?\n",
    "5. Esta pregunta pueden o no contestarla, quisiera saber la opinión al respecto del curso, que les gusto, que no les gusto, que cambiarian.\n",
    "\n",
    "Recuerden que la fecha de entrega de este proyecto es el **Viernes 28 de Mayo, 2021, a las 12 de la noche.**\n",
    "\n",
    "Muchas gracias por la atención que prestarón en el grupo y su interes en las clases. "
   ],
   "metadata": {
    "cell_id": "00000-13d0818b-7b86-428e-b4bf-eaeb5996daac",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00001-1d0a3b95-b46d-4e9d-b449-eee4d5c7a12b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "958c0fdd",
    "execution_start": 1622060437316,
    "execution_millis": 323,
    "deepnote_cell_type": "code"
   },
   "source": [
    "import re \n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import json\n",
    "from tensorflow.keras import models,layers,optimizers, callbacks, regularizers\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.special import softmax\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding,Conv2D,MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "source": [
    "Verificamos que vamos a utilizar procesador grafico, para correr las redes mas rapido."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "source": [
    "## Lectura Corpus"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00002-f5fe6231-82d4-4b5d-a3e7-b104a388eae9",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ddbd60df",
    "execution_start": 1622060438827,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": [
    "def get_file_data(fname):\n",
    "    file_contents = []\n",
    "    with open(fname, encoding='utf8',errors='ignore') as f:\n",
    "        file_contents = f.read()\n",
    "    text = []\n",
    "    for val in file_contents.split('\\n'):\n",
    "        val = re.sub(r'á','a',val)\n",
    "        val = re.sub(r'é','e',val)\n",
    "        val = re.sub(r'í','i',val)\n",
    "        val = re.sub(r'ó','o',val)\n",
    "        val = re.sub(r'ú','u',val)\n",
    "        val = re.sub(r'ü','u',val)\n",
    "        val = re.sub(r'Á','A',val)\n",
    "        val = re.sub(r'É','E',val)\n",
    "        val = re.sub(r'Í','I',val)\n",
    "        val = re.sub(r'Ó','O',val)\n",
    "        val = re.sub(r'Ú','U',val)\n",
    "        val = re.sub(r'ñ','n',val)\n",
    "        val = re.sub(r'Ñ','N',val)\n",
    "        sent = re.findall(r\"[A-Za-z]+|[.,!?;:¿¡]\", val)\n",
    "        line = ''\n",
    "        for words in sent:\n",
    "            if len(words) >= 1 :\n",
    "                line += ' ' + words\n",
    "        text.append(line)\n",
    "    return text\n",
    "\n",
    "# Función para obtener un vocabulario en función del texto procesado\n",
    "\n",
    "def generate_dictionary_data(text):\n",
    "    word_to_index= dict()\n",
    "    index_to_word = dict()\n",
    "    corpus = []\n",
    "    count = 0\n",
    "    vocab_size = 0\n",
    "    \n",
    "    for row in text:\n",
    "        for word in re.findall(r\"[A-Za-z]+|[.,!?;:¿¡]\", row):\n",
    "            word = word.lower()\n",
    "            corpus.append(word)\n",
    "            if word_to_index.get(word) == None:\n",
    "                word_to_index.update ( {word : count})\n",
    "                index_to_word.update ( {count : word })\n",
    "                count  += 1\n",
    "    vocab_size = len(word_to_index)\n",
    "    length_of_corpus = len(corpus)\n",
    "    \n",
    "    return word_to_index, index_to_word, corpus, vocab_size, length_of_corpus\n",
    "\n",
    "# Función para generar representaciones one hot de los vectores target y del corpus\n",
    "\n",
    "def get_one_hot_vectors(target_word, context_words, vocab_size, word_to_index):\n",
    "    \n",
    "    #Create an array of size = vocab_size filled with zeros\n",
    "    trgt_word_vector = np.zeros(vocab_size)\n",
    "    \n",
    "    #Get the index of the target_word according to the dictionary word_to_index. \n",
    "    index_of_word_dictionary = word_to_index.get(target_word) \n",
    "    \n",
    "    #Set the index to 1\n",
    "    trgt_word_vector[index_of_word_dictionary] = 1\n",
    "    \n",
    "    #Repeat same steps for context_words but in a loop\n",
    "    ctxt_word_vector = np.zeros(vocab_size)\n",
    "    \n",
    "    \n",
    "    for word in context_words:\n",
    "        index_of_word_dictionary = word_to_index.get(word) \n",
    "        ctxt_word_vector[index_of_word_dictionary] = 1\n",
    "        \n",
    "    return trgt_word_vector, ctxt_word_vector\n",
    "\n",
    "# Función para generar los datos de entrenamiento para la red neuronal que representa el modelo word2vec\n",
    "\n",
    "def generate_training_data_word2vec(corpus, window_size, vocab_size, word_to_index, length_of_corpus):\n",
    "\n",
    "    input_data = []\n",
    "    output_data = []\n",
    "\n",
    "    for i, word in enumerate(corpus):\n",
    "\n",
    "        index_target_word = i\n",
    "        target_word = word\n",
    "        context_words = []\n",
    "\n",
    "        #when target word is the first word\n",
    "        if i == 0:  \n",
    "\n",
    "            # trgt_word_index:(0), ctxt_word_index:(1,2)\n",
    "            context_words = [corpus[x] for x in range(i + 1 , window_size + 1)] \n",
    "\n",
    "\n",
    "        #when target word is the last word\n",
    "        elif i == len(corpus)-1:\n",
    "\n",
    "            # trgt_word_index:(9), ctxt_word_index:(8,7), length_of_corpus = 10\n",
    "            context_words = [corpus[x] for x in range(length_of_corpus - 2 ,length_of_corpus -2 - window_size  , -1 )]\n",
    "\n",
    "        #When target word is the middle word\n",
    "        else:\n",
    "\n",
    "            #Before the middle target word\n",
    "            before_target_word_index = index_target_word - 1\n",
    "            for x in range(before_target_word_index, before_target_word_index - window_size , -1):\n",
    "                if x >=0:\n",
    "                    context_words.extend([corpus[x]])\n",
    "\n",
    "            #After the middle target word\n",
    "            after_target_word_index = index_target_word + 1\n",
    "            for x in range(after_target_word_index, after_target_word_index + window_size):\n",
    "                if x < len(corpus):\n",
    "                    context_words.extend([corpus[x]])\n",
    "\n",
    "\n",
    "        trgt_word_vector, ctxt_word_vector = get_one_hot_vectors(target_word, context_words, vocab_size, word_to_index)\n",
    "        input_data.append(ctxt_word_vector)\n",
    "        output_data.append(trgt_word_vector)\n",
    "        \n",
    "    return np.array(input_data), np.array(output_data)\n",
    "\n",
    "def generate_training_data_LSTM1(corpus, word_to_index, window_size, vectors):\n",
    "    vocab_size, N = vectors.shape\n",
    "\n",
    "    input_data = []\n",
    "    output_data = []\n",
    "\n",
    "    for i, word in enumerate(corpus[window_size:]):\n",
    "        ctxt_words = corpus[i:window_size+i]\n",
    "        ctxt_matrix = np.zeros((window_size, vectors.shape[0]))\n",
    "        for j, ctxt in enumerate(ctxt_words):\n",
    "            idx = word_to_index[ctxt]\n",
    "            ctxt_matrix[j, :] = vectors[:, idx]\n",
    "        idx = word_to_index[word]\n",
    "        # words_vec = np.zeros(#pal)\n",
    "        # word_vec[idx] = 1\n",
    "        word_vec = vectors[:, idx]\n",
    "        input_data.append(ctxt_matrix)\n",
    "        output_data.append(word_vec)\n",
    "    \n",
    "    input_data = np.array(input_data)\n",
    "    output_data = np.array(output_data)\n",
    "\n",
    "    return input_data, output_data\n",
    "\n",
    "def generate_training_data_LSTM2(corpus, word_to_index, window_size, vectors):\n",
    "    vocab_size, N = vectors.shape\n",
    "\n",
    "    input_data = []\n",
    "    output_data = []\n",
    "\n",
    "    for i, word in enumerate(corpus[window_size:]):\n",
    "        ctxt_words = corpus[i:window_size+i]\n",
    "        ctxt_matrix = np.zeros((window_size, vectors.shape[0]))\n",
    "        for j, ctxt in enumerate(ctxt_words):\n",
    "            idx = word_to_index[ctxt]\n",
    "            ctxt_matrix[j, :] = vectors[:, idx]\n",
    "        idx = word_to_index[word]\n",
    "        word_vec = np.zeros(vectors.shape[1])\n",
    "        word_vec[idx] = 1\n",
    "        input_data.append(ctxt_matrix)\n",
    "        output_data.append(word_vec)\n",
    "    \n",
    "    input_data = np.array(input_data)\n",
    "    output_data = np.array(output_data)\n",
    "\n",
    "    return input_data, output_data"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 5171744789252252627\n, name: \"/device:GPU:0\"\ndevice_type: \"GPU\"\nmemory_limit: 510377984\nlocality {\n  bus_id: 1\n  links {\n  }\n}\nincarnation: 16033786581469252523\nphysical_device_desc: \"device: 0, name: NVIDIA GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00003-e24e5d37-b832-4a0f-96ff-927921e5db7a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a8a2cfcf",
    "execution_start": 1622060442115,
    "execution_millis": 9,
    "deepnote_cell_type": "code"
   },
   "source": [
    "fname = \"Conv1.txt\"\n",
    "C = 3 # Número de palabras de contexto a la derecha y a la izquierda\n",
    "text = get_file_data(fname)\n",
    "word_to_index,index_to_word,corpus,vocab_size,length_of_corpus = generate_dictionary_data(text)\n",
    "N = 300\n",
    "tipo = \"chatbot\""
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00004-ad1cff90-f99c-4f1f-84a3-fbd82a5eb8d6",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "63a02367",
    "execution_start": 1622060443575,
    "execution_millis": 8,
    "deepnote_cell_type": "code"
   },
   "source": [
    "vocab_size"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "323"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "source": [
    "## Word2vec\n",
    "\n",
    "Generamos el embebimiento de las palabras."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00004-1c0e3c17-aa99-4482-873b-090e41e71545",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bc6948fd",
    "execution_start": 1622060449441,
    "execution_millis": 47,
    "deepnote_cell_type": "code"
   },
   "source": [
    "input_data, output_data = generate_training_data_word2vec(corpus,C,vocab_size,word_to_index,length_of_corpus)"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00005-cde10b73-4ee3-4cc7-a6a1-7ff3ee6fa4ff",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "7acc63d9",
    "execution_start": 1621983852351,
    "execution_millis": 56,
    "deepnote_cell_type": "code"
   },
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(N, activation = 'relu', input_shape = (vocab_size,)))\n",
    "model.add(layers.Dense(vocab_size, activation = 'softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 300)               97200     \n_________________________________________________________________\ndense_1 (Dense)              (None, 323)               97223     \n=================================================================\nTotal params: 194,423\nTrainable params: 194,423\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00006-93009c51-f5c1-45ff-ba09-4b8be9381e0c",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "106d5353",
    "execution_start": 1621983852404,
    "execution_millis": 4653,
    "deepnote_cell_type": "code"
   },
   "source": [
    "cbs = [callbacks.ModelCheckpoint(join(\"word2vec_{}.h5\".format(tipo)), monitor='accuracy', save_best_only=True)]\n",
    "history = model.fit(input_data, output_data, epochs = 20, verbose=1, callbacks=cbs)\n",
    "history_dict = history.history\n",
    "json.dump(history_dict, open(join('word2vec_{}.json'.format(tipo)), 'w')) "
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "38/38 [==============================] - 2s 12ms/step - loss: 5.5153 - accuracy: 0.0955\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 4.5422 - accuracy: 0.1512\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 4.0545 - accuracy: 0.2309\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 3.7014 - accuracy: 0.2865\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 3.3574 - accuracy: 0.3056\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 3.0241 - accuracy: 0.3248\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 2.7030 - accuracy: 0.3621\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 2.3830 - accuracy: 0.4385\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 2.0628 - accuracy: 0.5199\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.7593 - accuracy: 0.5914\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.4743 - accuracy: 0.7076\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 1.2309 - accuracy: 0.7741\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.0219 - accuracy: 0.8380\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.8534 - accuracy: 0.8796\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.7176 - accuracy: 0.9028\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6106 - accuracy: 0.9327\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5230 - accuracy: 0.9477\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4523 - accuracy: 0.9543\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3936 - accuracy: 0.9618\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3457 - accuracy: 0.9701\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cargar el word2vec"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "00007-500336e7-5501-455b-88ef-40f7e1f4e5cb",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00008-1e60223d-ff62-42da-94fc-2061e531a5cc",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "91fd7904",
    "execution_start": 1622060455209,
    "execution_millis": 168,
    "deepnote_cell_type": "code"
   },
   "source": [
    "model = models.load_model(join('word2vec_{}.h5'.format(tipo)))\n",
    "w0 = model.get_weights()[2]\n",
    "w1 = model.get_weights()[0]\n",
    "vectors = 0.5*(w0+w1.T)\n",
    "del model"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "source": [
    "## Crear modelo de atencion\n",
    "\n",
    "Vamos a leer el texto y encontrar el Historial y Prediccion Y"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-a4b6a720-6a17-407d-8775-afdd2bee6798",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b9142ca2",
    "execution_start": 1622060466572,
    "execution_millis": 6,
    "deepnote_cell_type": "code"
   },
   "source": [
    "def read_data(fname,vectors,len_word2index):\n",
    "    file_contents = []\n",
    "    with open(fname, encoding='utf8',errors='ignore') as f:\n",
    "        file_contents = f.read()\n",
    "    text = []\n",
    "    general =[]\n",
    "    onehot_context = []\n",
    "    general_hot = []\n",
    "    max_palabras =0\n",
    "    for val in file_contents.split('\\n'):\n",
    "        contexto = []\n",
    "        val = re.sub(r'á','a',val)\n",
    "        val = re.sub(r'é','e',val)\n",
    "        val = re.sub(r'í','i',val)\n",
    "        val = re.sub(r'ó','o',val)\n",
    "        val = re.sub(r'ú','u',val)\n",
    "        val = re.sub(r'ü','u',val)\n",
    "        val = re.sub(r'Á','A',val)\n",
    "        val = re.sub(r'É','E',val)\n",
    "        val = re.sub(r'Í','I',val)\n",
    "        val = re.sub(r'Ó','O',val)\n",
    "        val = re.sub(r'Ú','U',val)\n",
    "        val = re.sub(r'ñ','n',val)\n",
    "        val = re.sub(r'Ñ','N',val)\n",
    "        va1 = re.sub(r'.','',val)\n",
    "        sent = re.findall(r\"[A-Za-z]+|[.,!?;:¿¡]\", val)\n",
    "        line = ''\n",
    "\n",
    "        conteo = 0\n",
    "        for words in sent:\n",
    "            words = words.lower()\n",
    "            if len(words) >= 1 :\n",
    "                idx = word_to_index[words]\n",
    "                vec_word = vectors[:,idx]\n",
    "                contexto.append(vec_word)\n",
    "                onehot_context.append(idx)\n",
    "                line += ' ' + words\n",
    "                conteo += 1\n",
    "        if (max_palabras < conteo): max_palabras = conteo\n",
    "        text.append(contexto)\n",
    "        context = np.array(contexto)\n",
    "        onehot_context = np.array(onehot_context)\n",
    "        encoded = to_categorical(onehot_context, num_classes=len_word2index)\n",
    "        general_hot.append(encoded)\n",
    "        onehot_context = []\n",
    "        general.append(contexto)\n",
    "    return general,max_palabras,general_hot"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00011-48c8b34a-7170-4960-b637-fb45bd953261",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ea7b2135",
    "execution_start": 1622060468600,
    "execution_millis": 20,
    "deepnote_cell_type": "code"
   },
   "source": [
    "general_contexto,max_palabras,general_hot = read_data(fname,vectors,len(word_to_index))\n"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "source": [
    "Creamos la funcion de obtener el O=\\[ Q | H \\]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00012-eed1ec15-98a1-41a7-9a48-fd06048fba12",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "157b11f9",
    "execution_start": 1622060595194,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": [
    "def get_O(contexto,quest,mayor):\n",
    "    quest1 = np.zeros((mayor,300))\n",
    "    H = []\n",
    "    for j in contexto:\n",
    "        for k in j:\n",
    "            H.append(k)\n",
    "\n",
    "    H = np.array(H)\n",
    "\n",
    "    for i in range(len(quest)):\n",
    "        quest1[i,:] = quest[i]\n",
    "    #quest = np.array(quest)\n",
    "\n",
    "    #print(\"h shape: \",H.shape)\n",
    "    #print(quest1.shape)\n",
    "\n",
    "    QIT = quest1 @ H.T\n",
    "    #print(QIT.shape)\n",
    "\n",
    "    a = softmax(QIT)\n",
    "\n",
    "    O = a @ H\n",
    "\n",
    "    return O,quest1"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00013-d47158b2-f436-4eda-a99a-8289f670dd30",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "3bccce5",
    "execution_start": 1622060628445,
    "execution_millis": 2,
    "deepnote_cell_type": "code"
   },
   "source": [
    "contexto = general_contexto[0:3]\n",
    "quest = general_contexto[3]"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00014-4c591b58-6fdd-4fc2-b5f6-795c4276ba9e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "568e185d",
    "execution_start": 1622060647033,
    "execution_millis": 3,
    "deepnote_cell_type": "code"
   },
   "source": [
    "O,quest1 = get_O(contexto,quest,max_palabras)"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "quest1.shape"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "00021-5658c1a5-efe3-40a1-b7e0-bf562873e966",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6084fbf6",
    "execution_start": 1622060658477,
    "execution_millis": 9,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(31, 300)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00013-85cb6f75-506a-46e0-9c63-5ff96f17c44c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "65d70ea0",
    "execution_start": 1622060619294,
    "execution_millis": 4,
    "deepnote_cell_type": "code"
   },
   "source": [
    "def Q_O(contexto,quest,mayor):\n",
    "    aux,quest1 = get_O(contexto,quest,mayor)\n",
    "    q =  np.concatenate((quest1,aux),axis=1)\n",
    "    return q,quest1"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00016-18da8266-7184-4853-b989-92af2302876d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6a38c01a",
    "execution_start": 1622060698230,
    "execution_millis": 8,
    "deepnote_cell_type": "code"
   },
   "source": [
    "q,quest1 = Q_O(contexto,quest,max_palabras)\n",
    "q.shape"
   ],
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(31, 600)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creacion Valores X y Y\n",
    "\n",
    "Se escoge el tamaño de la historia previa que será lh =4"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "00017-8ac1f21a-772a-4633-865a-8024291293f5",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00017-c1ab583b-12fb-472d-86b1-626d234301e2",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c01fea54",
    "execution_start": 1622060834164,
    "execution_millis": 191,
    "deepnote_cell_type": "code"
   },
   "source": [
    "lh = 4\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "# ONE HOT\n",
    "print(\"entrenando...\")\n",
    "for i in range(0,len(general_contexto)-lh-1):\n",
    "    H = general_contexto[i:lh+i]\n",
    "    quest = general_contexto[lh+i]\n",
    "    quest = np.array(quest)\n",
    "    q,quest1 = Q_O(H,quest,max_palabras)\n",
    "    X.append(q)\n",
    "    questy = general_hot[lh+i+1]\n",
    "    quest_o = np.zeros((max_palabras,vocab_size))\n",
    "    for i in range(questy.shape[0]):\n",
    "        quest_o[i,:] = questy[i]\n",
    "    Y.append(quest_o)\n",
    "\n",
    "print(\"termino...\")"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "entrenando...\ntermino...\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00020-77aa0ecc-6b92-4b6e-84ad-b7372de24b61",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "aa9d9ae5",
    "execution_start": 1622060840089,
    "execution_millis": 19,
    "deepnote_cell_type": "code"
   },
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "source": [
    "Creamos el modelo de prediccion utilizando atencion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00020-0a43f8b2-5baf-4212-8155-238970f29c7a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "51704abb",
    "execution_start": 1622062185335,
    "execution_millis": 9153,
    "deepnote_cell_type": "code"
   },
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(1000, input_shape=(X[0].shape),return_sequences=True,activity_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.LSTM(800, activation='tanh',return_sequences=True,activity_regularizer=regularizers.l2(0.01)))\n",
    "model.add(layers.Dense(500, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(322, activation='sigmoid'))\n",
    "model.add(Dense(Y[0].shape[1], activation='softmax'))\n",
    "print(model.summary())"
   ],
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm (LSTM)                  (None, 31, 1000)          6404000   \n_________________________________________________________________\ndropout (Dropout)            (None, 31, 1000)          0         \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 31, 800)           5763200   \n_________________________________________________________________\ndense_2 (Dense)              (None, 31, 500)           400500    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 31, 500)           0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 31, 322)           161322    \n_________________________________________________________________\ndense_4 (Dense)              (None, 31, 323)           104329    \n=================================================================\nTotal params: 12,833,351\nTrainable params: 12,833,351\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ]
  },
  {
   "source": [
    "En caso de cargar el modelo con la mejor epoca (Ya que es muy variable en su accuracy). Recomendamos hacerlo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('ModeloFinal_chatbot.h5')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "outputPrepend"
    ],
    "cell_id": "00023-b30b2617-4706-4ee5-bd8a-0ba552b2f7de",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9120d89e",
    "execution_start": 1622062227814,
    "execution_millis": 312459,
    "deepnote_cell_type": "code"
   },
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "cbs = [callbacks.ModelCheckpoint(join(\"ModeloFinal_chatbot.h5\"), monitor='accuracy', save_best_only=True)]\n",
    "history = model.fit(X, Y, epochs = 500, verbose=1, callbacks=cbs,batch_size=32,validation_split=0.2)"
   ],
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=============================] - 1s 225ms/step - loss: 1.4265 - accuracy: 0.0287 - val_loss: 1.9212 - val_accuracy: 0.0310\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.4246 - accuracy: 0.0287 - val_loss: 1.9182 - val_accuracy: 0.0310\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.4218 - accuracy: 0.0283 - val_loss: 1.9162 - val_accuracy: 0.6839\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.4204 - accuracy: 0.7387 - val_loss: 1.9153 - val_accuracy: 0.6839\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.4226 - accuracy: 0.7384 - val_loss: 1.9158 - val_accuracy: 0.6839\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.4262 - accuracy: 0.7387 - val_loss: 1.9143 - val_accuracy: 0.6839\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.4262 - accuracy: 0.7387 - val_loss: 1.9074 - val_accuracy: 0.6839\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.4199 - accuracy: 0.2577 - val_loss: 1.9069 - val_accuracy: 0.0310\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.4159 - accuracy: 0.0287 - val_loss: 1.9114 - val_accuracy: 0.0310\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.4171 - accuracy: 0.0283 - val_loss: 1.9144 - val_accuracy: 0.0310\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.4181 - accuracy: 0.0283 - val_loss: 1.9152 - val_accuracy: 0.0310\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.4216 - accuracy: 0.0283 - val_loss: 1.9138 - val_accuracy: 0.0310\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.4193 - accuracy: 0.0306 - val_loss: 1.9076 - val_accuracy: 0.6839\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.4179 - accuracy: 0.7384 - val_loss: 1.9047 - val_accuracy: 0.6839\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.4159 - accuracy: 0.7387 - val_loss: 1.9061 - val_accuracy: 0.6839\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 1.4138 - accuracy: 0.7384 - val_loss: 1.9109 - val_accuracy: 0.0310\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.4118 - accuracy: 0.0283 - val_loss: 1.9171 - val_accuracy: 0.0310\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.4120 - accuracy: 0.0283 - val_loss: 1.9136 - val_accuracy: 0.0310\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.4110 - accuracy: 0.0283 - val_loss: 1.9093 - val_accuracy: 0.0310\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.4156 - accuracy: 0.4992 - val_loss: 1.9068 - val_accuracy: 0.6839\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.4178 - accuracy: 0.7387 - val_loss: 1.9083 - val_accuracy: 0.6839\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.4159 - accuracy: 0.7387 - val_loss: 1.9138 - val_accuracy: 0.6839\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.4125 - accuracy: 0.4738 - val_loss: 1.9081 - val_accuracy: 0.0310\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.4105 - accuracy: 0.0283 - val_loss: 1.9033 - val_accuracy: 0.6826\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.4121 - accuracy: 0.7387 - val_loss: 1.9088 - val_accuracy: 0.6839\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.4148 - accuracy: 0.7384 - val_loss: 1.9112 - val_accuracy: 0.6839\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.4124 - accuracy: 0.7384 - val_loss: 1.9127 - val_accuracy: 0.6839\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.4092 - accuracy: 0.2405 - val_loss: 1.9096 - val_accuracy: 0.0310\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.4069 - accuracy: 0.0283 - val_loss: 1.9066 - val_accuracy: 0.0310\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.4057 - accuracy: 0.0290 - val_loss: 1.9061 - val_accuracy: 0.0310\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.4051 - accuracy: 0.4923 - val_loss: 1.9072 - val_accuracy: 0.6839\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.4041 - accuracy: 0.7393 - val_loss: 1.9109 - val_accuracy: 0.6839\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.4033 - accuracy: 0.7390 - val_loss: 1.9132 - val_accuracy: 0.0310\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.4035 - accuracy: 0.0290 - val_loss: 1.9099 - val_accuracy: 0.0310\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.3998 - accuracy: 0.0287 - val_loss: 1.9059 - val_accuracy: 0.0310\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.3956 - accuracy: 0.0290 - val_loss: 1.9019 - val_accuracy: 0.0310\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.3984 - accuracy: 0.0398 - val_loss: 1.8978 - val_accuracy: 0.6826\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.3957 - accuracy: 0.7393 - val_loss: 1.9013 - val_accuracy: 0.6839\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.4027 - accuracy: 0.7393 - val_loss: 1.9091 - val_accuracy: 0.6839\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.4014 - accuracy: 0.7393 - val_loss: 1.9057 - val_accuracy: 0.6839\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.3960 - accuracy: 0.7393 - val_loss: 1.9021 - val_accuracy: 0.6826\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.3944 - accuracy: 0.7400 - val_loss: 1.9026 - val_accuracy: 0.6826\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.3950 - accuracy: 0.7400 - val_loss: 1.9025 - val_accuracy: 0.6826\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.3960 - accuracy: 0.7400 - val_loss: 1.9012 - val_accuracy: 0.6826\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.3922 - accuracy: 0.7406 - val_loss: 1.9006 - val_accuracy: 0.6826\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.3886 - accuracy: 0.2672 - val_loss: 1.8984 - val_accuracy: 0.0310\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.3845 - accuracy: 0.2753 - val_loss: 1.8967 - val_accuracy: 0.6839\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.3828 - accuracy: 0.7410 - val_loss: 1.8968 - val_accuracy: 0.6839\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.3789 - accuracy: 0.4897 - val_loss: 1.8997 - val_accuracy: 0.0310\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.3769 - accuracy: 0.0310 - val_loss: 1.9047 - val_accuracy: 0.0310\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.3782 - accuracy: 0.0313 - val_loss: 1.9065 - val_accuracy: 0.0310\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.3735 - accuracy: 0.0310 - val_loss: 1.9058 - val_accuracy: 0.6839\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.3694 - accuracy: 0.7410 - val_loss: 1.9029 - val_accuracy: 0.6839\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.3685 - accuracy: 0.7423 - val_loss: 1.9009 - val_accuracy: 0.6839\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.3668 - accuracy: 0.7198 - val_loss: 1.8960 - val_accuracy: 0.0310\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.3664 - accuracy: 0.0316 - val_loss: 1.8956 - val_accuracy: 0.0310\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.3662 - accuracy: 0.0319 - val_loss: 1.9011 - val_accuracy: 0.0323\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.3675 - accuracy: 0.0336 - val_loss: 1.9032 - val_accuracy: 0.0323\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 1.3623 - accuracy: 0.5272 - val_loss: 1.9001 - val_accuracy: 0.6865\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 1.3608 - accuracy: 0.7442 - val_loss: 1.9023 - val_accuracy: 0.6839\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 1.3586 - accuracy: 0.5005 - val_loss: 1.9053 - val_accuracy: 0.0310\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.3563 - accuracy: 0.0352 - val_loss: 1.9085 - val_accuracy: 0.0323\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.3549 - accuracy: 0.0345 - val_loss: 1.9024 - val_accuracy: 0.0323\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.3518 - accuracy: 0.0577 - val_loss: 1.8946 - val_accuracy: 0.6839\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.3498 - accuracy: 0.2701 - val_loss: 1.8932 - val_accuracy: 0.6852\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.3502 - accuracy: 0.7445 - val_loss: 1.8964 - val_accuracy: 0.6852\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.3481 - accuracy: 0.7471 - val_loss: 1.8974 - val_accuracy: 0.6839\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.3486 - accuracy: 0.7462 - val_loss: 1.9014 - val_accuracy: 0.6852\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.3433 - accuracy: 0.7471 - val_loss: 1.9000 - val_accuracy: 0.6826\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.3415 - accuracy: 0.2753 - val_loss: 1.8999 - val_accuracy: 0.0310\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.3384 - accuracy: 0.0358 - val_loss: 1.8962 - val_accuracy: 0.0297\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.3378 - accuracy: 0.2968 - val_loss: 1.8946 - val_accuracy: 0.6826\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.3417 - accuracy: 0.7471 - val_loss: 1.8976 - val_accuracy: 0.6826\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.3404 - accuracy: 0.7221 - val_loss: 1.9000 - val_accuracy: 0.0297\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.3400 - accuracy: 0.0388 - val_loss: 1.8953 - val_accuracy: 0.6748\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.3366 - accuracy: 0.7462 - val_loss: 1.8934 - val_accuracy: 0.6826\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.3396 - accuracy: 0.7478 - val_loss: 1.8958 - val_accuracy: 0.6826\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.3373 - accuracy: 0.4992 - val_loss: 1.8985 - val_accuracy: 0.0297\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 1.3336 - accuracy: 0.0391 - val_loss: 1.8953 - val_accuracy: 0.0297\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.3317 - accuracy: 0.0407 - val_loss: 1.8963 - val_accuracy: 0.0297\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.3295 - accuracy: 0.0394 - val_loss: 1.8957 - val_accuracy: 0.6826\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.3311 - accuracy: 0.7491 - val_loss: 1.8933 - val_accuracy: 0.6826\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.3315 - accuracy: 0.7501 - val_loss: 1.8939 - val_accuracy: 0.6826\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 1.3267 - accuracy: 0.5044 - val_loss: 1.8977 - val_accuracy: 0.0297\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 1.3262 - accuracy: 0.2897 - val_loss: 1.8974 - val_accuracy: 0.6826\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.3241 - accuracy: 0.7501 - val_loss: 1.8863 - val_accuracy: 0.6839\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.3275 - accuracy: 0.7481 - val_loss: 1.8849 - val_accuracy: 0.6839\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.3269 - accuracy: 0.7481 - val_loss: 1.8837 - val_accuracy: 0.0310\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.3223 - accuracy: 0.0394 - val_loss: 1.8872 - val_accuracy: 0.0297\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.3214 - accuracy: 0.0401 - val_loss: 1.8902 - val_accuracy: 0.0297\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 1.3206 - accuracy: 0.5200 - val_loss: 1.8943 - val_accuracy: 0.6826\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 1.3194 - accuracy: 0.7504 - val_loss: 1.8948 - val_accuracy: 0.6826\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 1.3227 - accuracy: 0.7501 - val_loss: 1.8926 - val_accuracy: 0.6839\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 1.3242 - accuracy: 0.7504 - val_loss: 1.8875 - val_accuracy: 0.0297\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.3205 - accuracy: 0.0391 - val_loss: 1.8826 - val_accuracy: 0.0297\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 1s 260ms/step - loss: 1.3184 - accuracy: 0.0391 - val_loss: 1.8865 - val_accuracy: 0.0297\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.3159 - accuracy: 0.0401 - val_loss: 1.8933 - val_accuracy: 0.0297\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.3138 - accuracy: 0.2858 - val_loss: 1.8971 - val_accuracy: 0.6826\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.3131 - accuracy: 0.7520 - val_loss: 1.8921 - val_accuracy: 0.6826\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.3076 - accuracy: 0.2740 - val_loss: 1.8883 - val_accuracy: 0.0323\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.3080 - accuracy: 0.0424 - val_loss: 1.8844 - val_accuracy: 0.0323\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.3083 - accuracy: 0.0433 - val_loss: 1.8870 - val_accuracy: 0.0323\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.3050 - accuracy: 0.5184 - val_loss: 1.8895 - val_accuracy: 0.6852\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 1.3071 - accuracy: 0.7527 - val_loss: 1.8881 - val_accuracy: 0.6852\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.3080 - accuracy: 0.7517 - val_loss: 1.8845 - val_accuracy: 0.0310\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.3039 - accuracy: 0.0450 - val_loss: 1.8870 - val_accuracy: 0.0310\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 1.3006 - accuracy: 0.0440 - val_loss: 1.8919 - val_accuracy: 0.0310\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 1.3002 - accuracy: 0.0433 - val_loss: 1.8952 - val_accuracy: 0.0310\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.3010 - accuracy: 0.3030 - val_loss: 1.8965 - val_accuracy: 0.6839\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.2996 - accuracy: 0.7537 - val_loss: 1.8974 - val_accuracy: 0.6839\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.2980 - accuracy: 0.5002 - val_loss: 1.8856 - val_accuracy: 0.0310\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.2941 - accuracy: 0.0456 - val_loss: 1.8897 - val_accuracy: 0.0310\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.2950 - accuracy: 0.0433 - val_loss: 1.8933 - val_accuracy: 0.0310\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.2939 - accuracy: 0.0443 - val_loss: 1.8863 - val_accuracy: 0.0310\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.2968 - accuracy: 0.1730 - val_loss: 1.8862 - val_accuracy: 0.6852\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.2932 - accuracy: 0.7543 - val_loss: 1.8920 - val_accuracy: 0.6852\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.2893 - accuracy: 0.7559 - val_loss: 1.8936 - val_accuracy: 0.6826\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.2888 - accuracy: 0.2672 - val_loss: 1.8902 - val_accuracy: 0.0310\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 1.2892 - accuracy: 0.2920 - val_loss: 1.8882 - val_accuracy: 0.6839\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.2902 - accuracy: 0.7566 - val_loss: 1.8899 - val_accuracy: 0.6839\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.2897 - accuracy: 0.7550 - val_loss: 1.8872 - val_accuracy: 0.6839\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.2878 - accuracy: 0.2815 - val_loss: 1.8846 - val_accuracy: 0.0323\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.2880 - accuracy: 0.0446 - val_loss: 1.8879 - val_accuracy: 0.0310\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.2886 - accuracy: 0.0437 - val_loss: 1.8954 - val_accuracy: 0.0323\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.2857 - accuracy: 0.0456 - val_loss: 1.9017 - val_accuracy: 0.0323\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.2880 - accuracy: 0.0446 - val_loss: 1.9022 - val_accuracy: 0.0323\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.2913 - accuracy: 0.0446 - val_loss: 1.8943 - val_accuracy: 0.6826\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.2901 - accuracy: 0.7546 - val_loss: 1.8832 - val_accuracy: 0.6852\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.2938 - accuracy: 0.7550 - val_loss: 1.8847 - val_accuracy: 0.6852\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.2870 - accuracy: 0.7302 - val_loss: 1.8911 - val_accuracy: 0.0310\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.2833 - accuracy: 0.0463 - val_loss: 1.8946 - val_accuracy: 0.0310\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 1.2841 - accuracy: 0.2965 - val_loss: 1.8927 - val_accuracy: 0.6839\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.2821 - accuracy: 0.7566 - val_loss: 1.8899 - val_accuracy: 0.6839\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.2826 - accuracy: 0.7553 - val_loss: 1.8892 - val_accuracy: 0.6852\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 1.2797 - accuracy: 0.7553 - val_loss: 1.8864 - val_accuracy: 0.6852\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 1.2780 - accuracy: 0.7572 - val_loss: 1.8894 - val_accuracy: 0.6826\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.2801 - accuracy: 0.7566 - val_loss: 1.8918 - val_accuracy: 0.0323\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 1.2783 - accuracy: 0.0466 - val_loss: 1.8854 - val_accuracy: 0.0323\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.2797 - accuracy: 0.5184 - val_loss: 1.8893 - val_accuracy: 0.6852\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.2782 - accuracy: 0.7553 - val_loss: 1.8898 - val_accuracy: 0.6852\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_chat(corpus,vectors,len_word2index):\n",
    "    file_contents = []\n",
    "    text = []\n",
    "    general =[]\n",
    "    onehot_context = []\n",
    "    general_hot = []\n",
    "    max_palabras =0\n",
    "    for val in corpus.split('\\n'):\n",
    "        contexto = []\n",
    "        val = re.sub(r'á','a',val)\n",
    "        val = re.sub(r'é','e',val)\n",
    "        val = re.sub(r'í','i',val)\n",
    "        val = re.sub(r'ó','o',val)\n",
    "        val = re.sub(r'ú','u',val)\n",
    "        val = re.sub(r'ü','u',val)\n",
    "        val = re.sub(r'Á','A',val)\n",
    "        val = re.sub(r'É','E',val)\n",
    "        val = re.sub(r'Í','I',val)\n",
    "        val = re.sub(r'Ó','O',val)\n",
    "        val = re.sub(r'Ú','U',val)\n",
    "        val = re.sub(r'ñ','n',val)\n",
    "        val = re.sub(r'Ñ','N',val)\n",
    "        va1 = re.sub(r'.','',val)\n",
    "        sent = re.findall(r\"[A-Za-z]+|[.,!?;:¿¡]\", val)\n",
    "        line = ''\n",
    "\n",
    "        conteo = 0\n",
    "        for words in sent:\n",
    "            words = words.lower()\n",
    "            if len(words) >= 1 :\n",
    "                idx = word_to_index[words]\n",
    "                vec_word = vectors[:,idx]\n",
    "                contexto.append(vec_word)\n",
    "                onehot_context.append(idx)\n",
    "                line += ' ' + words\n",
    "                conteo += 1\n",
    "        if (max_palabras < conteo): max_palabras = conteo\n",
    "        text.append(contexto)\n",
    "        context = np.array(contexto)\n",
    "        onehot_context = np.array(onehot_context)\n",
    "        encoded = to_categorical(onehot_context, num_classes=len_word2index)\n",
    "        general_hot.append(encoded)\n",
    "        onehot_context = []\n",
    "        general.append(contexto)\n",
    "    return general,max_palabras,general_hot"
   ]
  },
  {
   "source": [
    "## Funcion CHATBOT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robot(oracion,corpus,pos,max_palabras=30):\n",
    "    print(\"---------\")\n",
    "    X = []\n",
    "    if pos != 0:\n",
    "        oracion = \"<start> \"+oracion+\" <eos>\"\n",
    "        corpus = corpus +'\\n'\n",
    "    else:\n",
    "        oracion = \"<start> \"+oracion+\" <eos>\"\n",
    "        corpus = oracion+\"\\n\"+oracion+ \"\\n\"+oracion+\"\\n\"+oracion+\"\\n\"\n",
    "        corpus = corpus + oracion\n",
    "\n",
    "    general_contexto,max_palabras2,general_hot = read_chat(corpus,vectors,len(word_to_index))\n",
    "\n",
    "    H = general_contexto[pos:lh+pos]\n",
    "    quest = general_contexto[lh+pos]\n",
    "\n",
    "\n",
    "    quest = np.array(quest)\n",
    "    q,quest1 = Q_O(H,quest,max_palabras)\n",
    "    q = tf.expand_dims(q, axis=0)\n",
    "    questy = (model.predict(q) > 0.2).astype(\"int32\")\n",
    "    indices = []\n",
    "    for i in range(questy.shape[1]):\n",
    "        ind = np.argmax(questy[0,i,:])\n",
    "        if ind !=0:\n",
    "            indices.append(ind)\n",
    "    oracion = ''\n",
    "    pos +=1\n",
    "    for i in indices:\n",
    "        oracion = oracion + ' '+index_to_word[i]\n",
    "    oracion = \"<start> \"+oracion+\" <eos>\"\n",
    "    print(\"Robot: \",oracion)\n",
    "    corpus = corpus +'\\n'+ oracion \n",
    "    return corpus,pos"
   ]
  },
  {
   "source": [
    "## EJEMPLO Funcionamiento Chatbot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<start> <begin> +'\n",
      "'Hola buenos días.+'\n",
      "' Hola ¿Como vas ? +'\n",
      "' bien bien y ¿tú? +'\n",
      "' bien bien ¿Qué haces?\n",
      "---------\n",
      "Robot:  <start>  hablando hablando contigo ¿ <eos>\n",
      "También estoy hablando contigo. \n",
      "---------\n",
      "Robot:  <start>  hola <eos>\n",
      "¿ Cuantos años tienes ?\n",
      "---------\n",
      "Robot:  <start>  bien ¿ <eos>\n"
     ]
    }
   ],
   "source": [
    "oracion = \"<start> <begin> +'\\n'\\\n",
    "Hola buenos días.+'\\n' \\\n",
    "Hola ¿Como vas ? +'\\n' \\\n",
    "bien bien y ¿tú? +'\\n' \\\n",
    "bien bien ¿Qué haces?\"\n",
    "print(oracion)\n",
    "corpus,pos = robot(oracion,'',0,max_palabras=31)\n",
    "oracion = \"También estoy hablando contigo. \"\n",
    "print(oracion)\n",
    "corpus,pos = robot(oracion,corpus,pos,max_palabras=31)\n",
    "oracion = \"¿ Cuantos años tienes ?\"\n",
    "print(oracion)\n",
    "corpus,pos = robot(oracion,corpus,pos,max_palabras=31)\n"
   ]
  },
  {
   "source": [
    "## PREGUNTAS\n",
    "\n",
    "1. ¿Qué diferencias encuentran en el sistema de generación de texto de este proyecto, comparado con el del proyecto anterior?\n",
    "\n",
    "    * El sistema de generacion de texto tenia en cuenta un rango de contexto de palabras anteriores para generar una nueva palabra. En este problema ya no tenemos un conjunto de palabras, si no un conjunto de historia que corresponde a oraciones anteriores del Chat. Ademas se 'contrasta' la relacion de las lineas anteriores con la linea actual para entender el contexto del chat que es el que denominamos O para generar una nueva oracion.\n",
    "\n",
    "2. ¿Considera qu ela estrategia de atención mejora el rendimiento del sistema de generación de texto? Justifique su respuesta.\n",
    "\n",
    "    * Si, la estrategia atencion mejora el rendimiento del sistema puesto tiene en cuenta la relacion que tiene la oracion actual con las anteriores y que tanto a cada palabra de cada una, cosa que dificilmente captaria un modelo neuronal simple. Algo que encontramos interesantes que es FUNDAMENTAL poner en el texto <Start> y <end> al final de cada oracion para que la red pudiera mejorar su precision y generar mejores textos.\n",
    "\n",
    "3. ¿Son los resultados obtenidos satisfactorios? ¿Cómo mejoraria los resultados del sistema implementado?\n",
    "    * Los resultados no son satisfactorios bien por que la prediccion no necesariamente corresponde a una buena prediccion esto pues la cantidad de datos (tamaño de corpus) es muy pequeña, ademas que parece que el espacio de entrenamiento no es convexo donde aveces pasa de una accuracy de 0.75 a 0.02, lo cual es un problema para el entrenamiento de la red. Sin embargo, de cierta manera el robot si es capaz de generar una respuesta que tenga sentido y capta cada oracion de la conversacion original. En nuestro problema solo predijo bien la primera linea, ya despues comienza a fallar un poco, esto pues se añade ruido al robot no responde correctamente.\n",
    "\n",
    "4. Si se les solicitará en sus trabajos utilizar los conocimientos que adquirieron en NLP para proponer propuestas de desarrollos y mejorar la competitividad de sus empresas, ¿Qué proyectos propondrian?\n",
    "\n",
    "    * Creemos depende del sector de la empresa. Bien ya con los conocimientos que tenemos podemos generar soluciones de crear un Chatbot de la empresa. Entender textos y mapearlos a un embebimiento donde se puede ver relacione entre ellos. Asi como crear soluciones que pueda captar audio y transformalo a texto. Miguel actualmente en el trabajo se encuentra ayudando en un proyecto de analizar sesgos de genero en las postuaciones de trabajo utilizando NLP, donde ha podido ayudar al grupo de trabajo dado los conocimientos aprendidos en NLP.\n",
    "\n",
    "\n",
    "5. Esta pregunta pueden o no contestarla, quisiera saber la opinión al respecto del curso, que les gusto, que no les gusto, que cambiarian.\n",
    "\n",
    "    * Nos parecio un buen curso, que explica lo fundamental si despues queremos profundizar y meternos mas de relleno en NLP. Es muy chevere ver que lo aprendido es de ultima actualidad. Siempre sera un reto explicar un tema muy nuevo. Gracias Profesor Alex."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd01baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253",
   "display_name": "Python 3.8.8 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "deepnote_notebook_id": "b9018e9e-632e-4491-a203-527b191fe266",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}